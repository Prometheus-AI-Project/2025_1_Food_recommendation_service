{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42362419",
   "metadata": {},
   "source": [
    "LLMì€ ì§ì ‘ ì—‘ì…€ í‘œë¥¼ ê²€ìƒ‰í•˜ê±°ë‚˜ ë²¡í„°í™” ë¶ˆê°€\n",
    "\n",
    "ì—‘ì…€ ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™” -> ë²¡í„°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7269d452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ë°¥ë¥˜' 'ë¹µ ë° ê³¼ìë¥˜' 'ë©´ ë° ë§Œë‘ë¥˜' 'ì£½ ë° ìŠ¤í”„ë¥˜' 'êµ­ ë° íƒ•ë¥˜' 'ì°Œê°œ ë° ì „ê³¨ë¥˜' 'ì°œë¥˜' 'êµ¬ì´ë¥˜'\n",
      " 'ì „Â·ì  ë° ë¶€ì¹¨ë¥˜' 'ë³¶ìŒë¥˜' 'ì¡°ë¦¼ë¥˜' 'íŠ€ê¹€ë¥˜' 'ë‚˜ë¬¼Â·ìˆ™ì±„ë¥˜' 'ìƒì±„Â·ë¬´ì¹¨ë¥˜' 'ê¹€ì¹˜ë¥˜' 'ì “ê°ˆë¥˜' 'ì¥ì•„ì°ŒÂ·ì ˆì„ë¥˜'\n",
      " 'ìŒë£Œ ë° ì°¨ë¥˜' 'ìˆ˜Â·ì¡°Â·ì–´Â·ìœ¡ë¥˜' 'ìœ ì œí’ˆë¥˜ ë° ë¹™ê³¼ë¥˜']\n"
     ]
    }
   ],
   "source": [
    "# ì‹í’ˆëŒ€ë¶„ë¥˜ëª… ì»¬ëŸ¼ì˜ ê³ ìœ ê°’(ì¢…ë¥˜) ì¶œë ¥\n",
    "import pandas as pd\n",
    "\n",
    "EXCEL_PATH = r\"C:\\Users\\thdwo\\OneDrive\\ë°”íƒ• í™”ë©´\\í”„ë©” í”„ì \\db\\filtered_db.xlsx\"\n",
    "db = pd.read_excel(EXCEL_PATH)\n",
    "\n",
    "print(db['ì‹í’ˆëŒ€ë¶„ë¥˜ëª…'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db56a63e",
   "metadata": {},
   "source": [
    "ì¹´í…Œê³ ë¦¬ ì¹¼ëŸ¼ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db17edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ í•¨ìˆ˜ ì •ì˜\n",
    "def assign_category(row):\n",
    "    category = row['ì‹í’ˆëŒ€ë¶„ë¥˜ëª…']\n",
    "    name = str(row['ì‹í’ˆëª…'])  # ìŒì‹ëª…ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹œ ì‚¬ìš©\n",
    "\n",
    "    if category == 'ë°¥ë¥˜':\n",
    "        return 'ë°¥'\n",
    "    elif category in ['ì£½ ë° ìŠ¤í”„ë¥˜', 'êµ­ ë° íƒ•ë¥˜', 'ì°Œê°œ ë° ì „ê³¨ë¥˜']:\n",
    "        return 'êµ­'\n",
    "    elif category in [\n",
    "        'ì°œë¥˜', 'êµ¬ì´ë¥˜', 'ì „Â·ì  ë° ë¶€ì¹¨ë¥˜', 'ë³¶ìŒë¥˜', 'ì¡°ë¦¼ë¥˜',\n",
    "        'íŠ€ê¹€ë¥˜', 'ë‚˜ë¬¼Â·ìˆ™ì±„ë¥˜', 'ìƒì±„Â·ë¬´ì¹¨ë¥˜', 'ê¹€ì¹˜ë¥˜', 'ì “ê°ˆë¥˜',\n",
    "        'ì¥ì•„ì°ŒÂ·ì ˆì„ë¥˜', 'ìˆ˜Â·ì¡°Â·ì–´Â·ìœ¡ë¥˜'\n",
    "    ]:\n",
    "        return 'ë°˜ì°¬'\n",
    "    elif category == 'ë©´ ë° ë§Œë‘ë¥˜':\n",
    "        if 'ë§Œë‘' in name:\n",
    "            return 'ë°˜ì°¬'\n",
    "        else:\n",
    "            return 'ë©´'\n",
    "    elif any(word in name.lower() for word in ['ë²„ê±°', 'í”¼ì', 'í•«ë„ê·¸']):\n",
    "        return 'ì–‘ì‹'\n",
    "    elif category in ['ë¹µ ë° ê³¼ìë¥˜', 'ìŒë£Œ ë° ì°¨ë¥˜', 'ìœ ì œí’ˆë¥˜ ë° ë¹™ê³¼ë¥˜']:\n",
    "        return 'ë””ì €íŠ¸ & ë¹µ'\n",
    "    else:\n",
    "        return 'ê¸°íƒ€'\n",
    "\n",
    "# ì¹´í…Œê³ ë¦¬ ì—´ ì±„ìš°ê¸°\n",
    "df['ì¹´í…Œê³ ë¦¬'] = df.apply(assign_category, axis=1)\n",
    "\n",
    "# ì €ì¥\n",
    "df.to_excel(r\"C:\\Users\\thdwo\\OneDrive\\ë°”íƒ• í™”ë©´\\í”„ë©” í”„ì \\db\\filtered_db_add_cate.xlsx\", index=False)\n",
    "\n",
    "print(\"ì¹´í…Œê³ ë¦¬ ì—´ì´ ì±„ì›Œì¡Œê³ , íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aff23d6",
   "metadata": {},
   "source": [
    "RAG vectorstore ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f08eea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thdwo\\AppData\\Local\\Temp\\ipykernel_44572\\3349078971.py:26: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ FAISS ë° ì„ë² ë”© ë¡œë“œ ì˜ˆì‹œ\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# ğŸ”— íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "EXCEL_PATH = r\"C:\\Users\\thdwo\\OneDrive\\ë°”íƒ• í™”ë©´\\í”„ë©” í”„ì \\db\\filtered_db_add_cate.xlsx\"\n",
    "VECTORSTORE_DIR = \"./vectorstore_json\"\n",
    "\n",
    "# âœ… ì—‘ì…€ íŒŒì¼ ë¡œë“œ\n",
    "df = pd.read_excel(EXCEL_PATH)\n",
    "\n",
    "# ğŸš« 'ì˜ì–‘ì„±ë¶„í•¨ëŸ‰ê¸°ì¤€ëŸ‰' ì—´ ì œì™¸\n",
    "if 'ì˜ì–‘ì„±ë¶„í•¨ëŸ‰ê¸°ì¤€ëŸ‰' in df.columns:\n",
    "    df = df.drop(columns=['ì˜ì–‘ì„±ë¶„í•¨ëŸ‰ê¸°ì¤€ëŸ‰'])\n",
    "\n",
    "# ğŸ”„ ê° í–‰ì„ JSON í˜•íƒœë¡œ ë³€í™˜\n",
    "def row_to_json(row):\n",
    "    return json.dumps(row.to_dict(), ensure_ascii=False)\n",
    "\n",
    "# ğŸ“œ ì „ì²´ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "docs = df.apply(row_to_json, axis=1).tolist()\n",
    "\n",
    "# ğŸ§  ì„ë² ë”© ëª¨ë¸ ë¡œë“œ\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# ğŸ—‚ï¸ FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "vectorstore = FAISS.from_texts(docs, embedding_model)\n",
    "\n",
    "# ğŸ’¾ ë²¡í„°ìŠ¤í† ì–´ ì €ì¥\n",
    "vectorstore.save_local(VECTORSTORE_DIR)\n",
    "\n",
    "print(\"âœ… ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ì™„ë£Œ!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
